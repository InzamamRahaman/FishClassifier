{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import torchvision\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader,Dataset\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.utils\n",
    "import numpy as np\n",
    "import random\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import PIL.ImageOps    \n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from pathlib import Path\n",
    "import torch.nn.init as init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def imshow(img,text=None,should_save=False):\n",
    "    npimg = img.numpy()\n",
    "    plt.axis(\"off\")\n",
    "    if text:\n",
    "        plt.text(75, 8, text, style='italic',fontweight='bold',\n",
    "            bbox={'facecolor':'white', 'alpha':0.8, 'pad':10})\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()    \n",
    "\n",
    "def show_plot(iteration,loss):\n",
    "    plt.plot(iteration,loss)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SiameseNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SiameseNetwork, self).__init__()\n",
    "        self.ground_truth = None\n",
    "        self.labels = None \n",
    "        self.img_transform_pre = transforms.Compose([\n",
    "            transforms.Resize((128, 128)),\n",
    "            transforms.ToTensor()\n",
    "        ])\n",
    "        self.img_transform_post = transforms.Compose([\n",
    "            transforms.ToPILImage(),\n",
    "            transforms.Resize((128, 128)),\n",
    "            transforms.ToTensor()\n",
    "        ])\n",
    "        self.cnn1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 6, kernel_size=5),\n",
    "            nn.PReLU(),\n",
    "            nn.AvgPool2d(2, stride=2),\n",
    "            nn.Conv2d(6, 2, kernel_size=5),\n",
    "            nn.PReLU(),\n",
    "            nn.AvgPool2d(2, stride=2))\n",
    "\n",
    "#         self.fc1 = nn.Sequential(\n",
    "#             #nn.Linear(50 * 4 * 4, 500),\n",
    "#             nn.Linear(2 * 61 * 61, 512),\n",
    "#             nn.ReLU(inplace=True),\n",
    "#             nn.Linear(512, 256),\n",
    "#             nn.Linear(256, 128),\n",
    "#             nn.Linear(128, 32),\n",
    "#             nn.Linear(32, 2))\n",
    "        self.f1 = nn.Linear(2 * 29 * 29, 1024)\n",
    "        self.t = nn.PReLU()\n",
    "        self.f2 = nn.Linear(1024, 256)\n",
    "        self.f3 = nn.Linear(256, 64)\n",
    "        self.f4 = nn.Linear(64, 16)\n",
    "        self.f5 = nn.Linear(16, 4)\n",
    "        self.f6 = nn.Linear(4, 2)\n",
    "        \n",
    "        init.xavier_uniform(self.f1.weight, gain=np.sqrt(2))\n",
    "        init.xavier_uniform(self.f2.weight, gain=np.sqrt(2))\n",
    "        init.xavier_uniform(self.f3.weight, gain=np.sqrt(2))\n",
    "        init.xavier_uniform(self.f4.weight, gain=np.sqrt(2))\n",
    "        init.xavier_uniform(self.f5.weight, gain=np.sqrt(2))\n",
    "        init.xavier_uniform(self.f6.weight, gain=np.sqrt(2))\n",
    "\n",
    "    def forward_once(self, x):\n",
    "        output = self.cnn1(x)\n",
    "        #print(output.shape)\n",
    "        #exit()\n",
    "        output = output.view(output.size()[0], -1)\n",
    "        output = self.f1(output)\n",
    "        self.t(output)\n",
    "        output = self.f2(output)\n",
    "        output = self.f3(output)\n",
    "        output = self.f4(output)\n",
    "        output = self.f5(output)\n",
    "        output = self.f6(output)\n",
    "        return output\n",
    "\n",
    "    def forward(self, input1, input2):\n",
    "        output1 = self.forward_once(input1)\n",
    "        output2 = self.forward_once(input2)\n",
    "        return output1, output2\n",
    "    \n",
    "    def regularize(self, lam=0.00055):\n",
    "        loss = Variable(torch.zeros(1))\n",
    "        for param in self.parameters():\n",
    "            loss += torch.norm(param)\n",
    "        loss *= lam\n",
    "        return loss\n",
    "    \n",
    "    def process_image(self, img_array):\n",
    "        return self.img_transform_post(img_array)\n",
    "    \n",
    "    def classify(self, current, omit=None):\n",
    "        #current = Image.fromarray(current)\n",
    "        current = self.img_transform_post(current)\n",
    "        #current = current.unsqueeze(0)\n",
    "        inputs1 = []\n",
    "        inputs2 = []\n",
    "        for i, t in enumerate(self.ground_truth):\n",
    "            if omit is None or i != omit:\n",
    "                inputs1.append(t.unsqueeze(0))\n",
    "                inputs2.append(current.unsqueeze(0))\n",
    "        inputs1 = Variable(torch.cat(inputs1))\n",
    "        inputs2 = Variable(torch.cat(inputs2))\n",
    "        output1, output2 = self(inputs1, inputs2)\n",
    "        distances = F.pairwise_distance(output1, output2).data.numpy()\n",
    "        i = 0\n",
    "        for j, d in enumerate(distances):\n",
    "            if distances[j] < distances[i]:\n",
    "                i = j\n",
    "        return distances, i, self.labels[i]\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ContrastiveLoss(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Contrastive loss function.\n",
    "    Based on: http://yann.lecun.com/exdb/publis/pdf/hadsell-chopra-lecun-06.pdf\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, margin=2.0):\n",
    "        super(ContrastiveLoss, self).__init__()\n",
    "        self.margin = margin\n",
    "\n",
    "    def forward(self, output1, output2, label):\n",
    "        euclidean_distance = F.pairwise_distance(output1, output2)\n",
    "        #print(euclidean_distance)\n",
    "        #print(label)\n",
    "        d = torch.pow(euclidean_distance, 2)\n",
    "        e =  (1-label)\n",
    "        part1 = 0.5 * d * e.float()\n",
    "        part2 = 0.5 * label.float() * torch.pow(torch.clamp(self.margin - euclidean_distance, min=0.0), 2)\n",
    "        \n",
    "        loss_contrastive = torch.mean(part1 + part2)\n",
    "\n",
    "        return loss_contrastive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fishes = ['lionfish', 'bluecrab']\n",
    "training_num = [1,2,3,4,5,6,7,8]\n",
    "testing_num = [9,10,11,12]\n",
    "path = Path('../data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((128, 128)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "raw_data = []\n",
    "labels = []\n",
    "for fish in fishes:\n",
    "    for num in training_num:\n",
    "        input_path = path / f'{fish}_{num}.jpg'\n",
    "        img = Image.open(input_path)\n",
    "        arr = transform(img)\n",
    "#         arr = np.array(img)\n",
    "# #         arr = torch.FloatTensor(arr)\n",
    "# #         arr = arr.unsqueeze(0)\n",
    "        raw_data.append(arr)\n",
    "        labels.append(fish)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      "1.00000e-02 *\n",
      "  6.0818\n",
      "[torch.FloatTensor of size 1]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "net = SiameseNetwork()\n",
    "criterion = ContrastiveLoss(margin=7.0)\n",
    "optimizer = optim.Adagrad(net.parameters(),lr = 0.0005 )\n",
    "print(net.regularize())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "net.ground_truth = raw_data\n",
    "net.labels = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[  1.41421356e-06],\n",
       "        [  1.54228121e-01],\n",
       "        [  2.20717594e-01],\n",
       "        [  2.52739400e-01],\n",
       "        [  1.88162044e-01],\n",
       "        [  4.02691633e-01],\n",
       "        [  2.40279555e-01],\n",
       "        [  2.40279555e-01],\n",
       "        [  2.41650701e-01],\n",
       "        [  3.56941849e-01],\n",
       "        [  2.41347313e-01],\n",
       "        [  1.02442428e-01],\n",
       "        [  3.15337449e-01],\n",
       "        [  2.70264030e-01],\n",
       "        [  3.01466614e-01],\n",
       "        [  3.56941938e-01]], dtype=float32), 0, 'lionfish')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "net.classify(torch.FloatTensor(Variable(raw_data[0]).data.numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "240\n"
     ]
    }
   ],
   "source": [
    "x1 = []\n",
    "x2 = []\n",
    "targets = []\n",
    "count = 0\n",
    "for idx1, (im1, l1) in enumerate(zip(raw_data, labels)):\n",
    "    i = im1.unsqueeze(0)\n",
    "    for idx2, (im2, l2) in enumerate(zip(raw_data, labels)):\n",
    "        if idx1 != idx2:\n",
    "            j = im2.unsqueeze(0)\n",
    "            target = 0 if l1 == l2 else 1\n",
    "            targets.append(target)\n",
    "            x1.append(i)\n",
    "            x2.append(j)\n",
    "            count += 1\n",
    "\n",
    "targets = torch.LongTensor(targets)\n",
    "x1 = torch.cat(x1)\n",
    "x2 = torch.cat(x2)\n",
    "print(count)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at 1 is \n",
      " 7.1286\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Loss at 2 is \n",
      " 7.1286\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Loss at 3 is \n",
      " 7.1285\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Loss at 4 is \n",
      " 7.1284\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Loss at 5 is \n",
      " 7.1284\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Loss at 6 is \n",
      " 7.1283\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Loss at 7 is \n",
      " 7.1283\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Loss at 8 is \n",
      " 7.1282\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Loss at 9 is \n",
      " 7.1282\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Loss at 10 is \n",
      " 7.1281\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Loss at 11 is \n",
      " 7.1281\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Loss at 12 is \n",
      " 7.1280\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Loss at 13 is \n",
      " 7.1280\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Loss at 14 is \n",
      " 7.1279\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Loss at 15 is \n",
      " 7.1279\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Loss at 16 is \n",
      " 7.1279\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Loss at 17 is \n",
      " 7.1278\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Loss at 18 is \n",
      " 7.1278\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Loss at 19 is \n",
      " 7.1278\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Loss at 20 is \n",
      " 7.1277\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Loss at 21 is \n",
      " 7.1277\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Loss at 22 is \n",
      " 7.1277\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Loss at 23 is \n",
      " 7.1276\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Loss at 24 is \n",
      " 7.1276\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Loss at 25 is \n",
      " 7.1276\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Loss at 26 is \n",
      " 7.1276\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Loss at 27 is \n",
      " 7.1276\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Loss at 28 is \n",
      " 7.1275\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Loss at 29 is \n",
      " 7.1275\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Loss at 30 is \n",
      " 7.1275\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Loss at 31 is \n",
      " 7.1275\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Loss at 32 is \n",
      " 7.1275\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Loss at 33 is \n",
      " 7.1274\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Loss at 34 is \n",
      " 7.1274\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Loss at 35 is \n",
      " 7.1274\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Loss at 36 is \n",
      " 7.1274\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Loss at 37 is \n",
      " 7.1274\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Loss at 38 is \n",
      " 7.1274\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Loss at 39 is \n",
      " 7.1273\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Loss at 40 is \n",
      " 7.1273\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Loss at 41 is \n",
      " 7.1273\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Loss at 42 is \n",
      " 7.1273\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Loss at 43 is \n",
      " 7.1273\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Loss at 44 is \n",
      " 7.1273\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Loss at 45 is \n",
      " 7.1273\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Loss at 46 is \n",
      " 7.1272\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Loss at 47 is \n",
      " 7.1272\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Loss at 48 is \n",
      " 7.1272\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Loss at 49 is \n",
      " 7.1272\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Loss at 50 is \n",
      " 7.1272\n",
      "[torch.FloatTensor of size 1]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 50\n",
    "for epoch in range(num_epochs):\n",
    "    optimizer.zero_grad()\n",
    "    input1 = Variable(x1)\n",
    "    input2 = Variable(x2)\n",
    "    correct = Variable(targets)\n",
    "    output1, output2 = net(input1, input2)\n",
    "    loss = criterion(output1, output2, correct)\n",
    "    loss += net.regularize()\n",
    "    print(f'Loss at {epoch + 1} is {loss.data}')\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((128, 128)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "raw_data1 = []\n",
    "labels1 = []\n",
    "for fish in fishes:\n",
    "    for num in testing_num:\n",
    "        input_path = path / f'{fish}_{num}.jpg'\n",
    "        img = Image.open(input_path)\n",
    "        arr = transform(img)\n",
    "#         arr = np.array(img)\n",
    "# #         arr = torch.FloatTensor(arr)\n",
    "# #         arr = arr.unsqueeze(0)\n",
    "        raw_data1.append(arr)\n",
    "        labels1.append(fish)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "im1 = Variable(raw_data[4]).unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "im2 = Variable(raw_data1[1]).unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x, y = net(im1, im2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 3.1870\n",
       "[torch.FloatTensor of size 1x1]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.pairwise_distance(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['lionfish',\n",
       " 'lionfish',\n",
       " 'lionfish',\n",
       " 'lionfish',\n",
       " 'bluecrab',\n",
       " 'bluecrab',\n",
       " 'bluecrab',\n",
       " 'bluecrab']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['lionfish',\n",
       " 'lionfish',\n",
       " 'lionfish',\n",
       " 'lionfish',\n",
       " 'lionfish',\n",
       " 'lionfish',\n",
       " 'lionfish',\n",
       " 'lionfish',\n",
       " 'bluecrab',\n",
       " 'bluecrab',\n",
       " 'bluecrab',\n",
       " 'bluecrab',\n",
       " 'bluecrab',\n",
       " 'bluecrab',\n",
       " 'bluecrab',\n",
       " 'bluecrab']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def classify(ground_truth, labels, net, current, omit=None):\n",
    "    inputs1 = []\n",
    "    inputs2 = []\n",
    "    for i, t in enumerate(ground_truth):\n",
    "        if omit is None or i != omit:\n",
    "            inputs1.append(t.unsqueeze(0))\n",
    "            inputs2.append(current.unsqueeze(0))\n",
    "    inputs1 = Variable(torch.cat(inputs1))\n",
    "    inputs2 = Variable(torch.cat(inputs2))\n",
    "    output1, output2 = net(inputs1, inputs2)\n",
    "    distances = F.pairwise_distance(output1, output2).data.numpy()\n",
    "    i = 0\n",
    "    for j, d in enumerate(distances):\n",
    "        if distances[j] < distances[i]:\n",
    "            i = j\n",
    "    return distances, i, labels[i]\n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bluecrab - lionfish\n",
      "lionfish - lionfish\n",
      "bluecrab - lionfish\n",
      "lionfish - lionfish\n",
      "bluecrab - bluecrab\n",
      "bluecrab - bluecrab\n",
      "bluecrab - bluecrab\n",
      "bluecrab - bluecrab\n"
     ]
    }
   ],
   "source": [
    "for idx, l in enumerate(labels1):\n",
    "    a, b, c = classify(raw_data, labels, net, raw_data1[idx])\n",
    "    print(f'{c} - {l}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lionfish - lionfish\n",
      "lionfish - lionfish\n",
      "lionfish - lionfish\n",
      "lionfish - lionfish\n",
      "lionfish - lionfish\n",
      "bluecrab - lionfish\n",
      "lionfish - lionfish\n",
      "lionfish - lionfish\n",
      "bluecrab - bluecrab\n",
      "bluecrab - bluecrab\n",
      "lionfish - bluecrab\n",
      "lionfish - bluecrab\n",
      "bluecrab - bluecrab\n",
      "bluecrab - bluecrab\n",
      "lionfish - bluecrab\n",
      "bluecrab - bluecrab\n"
     ]
    }
   ],
   "source": [
    "for idx, l in enumerate(labels):\n",
    "    a, b, c = classify(raw_data, labels, net, raw_data[idx], idx)\n",
    "    print(f'{c} - {l}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 2.54667044],\n",
       "        [ 1.0463438 ],\n",
       "        [ 1.78616011],\n",
       "        [ 1.79840863],\n",
       "        [ 3.18704271],\n",
       "        [ 2.51923275],\n",
       "        [ 0.99314064],\n",
       "        [ 0.99314064],\n",
       "        [ 3.17802095],\n",
       "        [ 3.84716439],\n",
       "        [ 1.83481371],\n",
       "        [ 2.21836829],\n",
       "        [ 4.03227758],\n",
       "        [ 3.70564222],\n",
       "        [ 3.70245957],\n",
       "        [ 3.84716392]], dtype=float32), 6, 'lionfish')"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.classify(raw_data1[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['lionfish',\n",
       " 'lionfish',\n",
       " 'lionfish',\n",
       " 'lionfish',\n",
       " 'bluecrab',\n",
       " 'bluecrab',\n",
       " 'bluecrab',\n",
       " 'bluecrab']"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/inzamamrahaman/anaconda3/lib/python3.6/site-packages/torch/serialization.py:158: UserWarning: Couldn't retrieve source code for container of type SiameseNetwork. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    }
   ],
   "source": [
    "torch.save(net, 'recognizer.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
